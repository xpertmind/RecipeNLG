{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "setup_workshop.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLg5AutUlOFcVhOXIYF+GS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xpertmind/RecipeNLG/blob/main/setup_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Import the libraries needed and define some variables \n"
      ],
      "metadata": {
        "id": "254Wz7odEXqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0LJMPi8wa6T",
        "outputId": "e85b1575-1261-48f1-aa98-f892c7fd2684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyTigerGraph\n",
            "  Downloading pyTigerGraph-0.0.9.9.2-py3-none-any.whl (22 kB)\n",
            "Collecting validators\n",
            "  Downloading validators-0.19.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pyTigerGraph) (2.23.0)\n",
            "Collecting pyTigerDriver\n",
            "  Downloading pyTigerDriver-1.0.14-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyTigerGraph) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTigerGraph) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTigerGraph) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyTigerGraph) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyTigerGraph) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pyTigerGraph) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pyTigerGraph) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pyTigerGraph) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pyTigerGraph) (1.24.3)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->pyTigerGraph) (4.4.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.19.0-py3-none-any.whl size=19553 sha256=dc33b447514358e7f102045e90c8599c818e0942ddbfd10f04bc10d764fc251d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/5d/69/ff53a908b9f14fb7730a58fdede0fac4cdc99ef3624ec76d05\n",
            "Successfully built validators\n",
            "Installing collected packages: validators, pyTigerDriver, pyTigerGraph\n",
            "Successfully installed pyTigerDriver-1.0.14 pyTigerGraph-0.0.9.9.2 validators-0.19.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyTigerGraph\n",
        "!pip install pandas\n",
        "chunk_size = 5000\n",
        "# Imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import pyTigerGraph as tg\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please put here your specific setup variables:"
      ],
      "metadata": {
        "id": "FT38qoFCN0jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tghost=\"https://bs-dis.i.tgcloud.io\"\n",
        "tguser=\"tigergraph\" # default!\n",
        "tgpass=\"geheim\""
      ],
      "metadata": {
        "id": "yvv34S3-OLVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TG\n",
        "tgconn = tg.TigerGraphConnection(host=tghost, username=tguser, password=tgpass, gsqlVersion=\"3.5.0\")"
      ],
      "metadata": {
        "id": "gwr3SrOzNvpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's start with DDL (vertices and edges)"
      ],
      "metadata": {
        "id": "6HNpwdo2Snmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/xpertmind/RecipeNLG/main/setup.gsql -O setup.gsql\n",
        "with open(\"./setup.gsql\") as f:\n",
        "    contents = f.read()\n",
        "print(tgconn.gsql(contents, options=[]))\n",
        "# now connect to graph \n",
        "tgconn.graphname = \"RecipeNLG\" \n",
        "secret = tgconn.createSecret(\"Workshop_IPYNB\")\n",
        "print(\"Secret -> \"+secret)\n",
        "token = tgconn.getToken(secret)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tveqsMGSt-h",
        "outputId": "2282d9e8-5885-4bcf-ca86-8ed103e5fdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-06 04:38:59--  https://raw.githubusercontent.com/xpertmind/RecipeNLG/main/setup.gsql\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4435 (4.3K) [text/plain]\n",
            "Saving to: ‘setup.gsql’\n",
            "\n",
            "\rsetup.gsql            0%[                    ]       0  --.-KB/s               \rsetup.gsql          100%[===================>]   4.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-06 04:39:00 (52.1 MB/s) - ‘setup.gsql’ saved [4435/4435]\n",
            "\n",
            "The graph RecipeNLG is created.\n",
            "Successfully created schema change jobs: [create_ddl_recipe].\n",
            "\n",
            "Current graph version 0\n",
            "Trying to add vertex recipes.\n",
            "Trying to add vertex directions.\n",
            "Trying to add vertex ingredients.\n",
            "Trying to add vertex keywords.\n",
            "Trying to add edge recipe_keyword.\n",
            "Trying to add edge recipe_ingredient.\n",
            "Trying to add edge ingredient_recipe.\n",
            "Trying to add edge howto_cook.\n",
            "Trying to add edge rev_howto_cook.\n",
            "Kick off job create_ddl_recipe\n",
            "\n",
            "Graph RecipeNLG update to new version 1\n",
            "The job create_ddl_recipe completes in 15.051 seconds!\n",
            "Successfully dropped jobs on the graph 'RecipeNLG': [create_ddl_recipe].\n",
            "Using graph 'RecipeNLG'\n",
            "Successfully created queries: [a_simple_select].\n",
            "Successfully created queries: [b_all_recipes_for_a_keyword].\n",
            "Successfully created queries: [c_multi_hops].\n",
            "Successfully created queries: [d_recipe_counter].\n",
            "Successfully created queries: [e_recipe_counter_2].\n",
            "Successfully created queries: [f_recipe_complexity].\n",
            "Successfully created queries: [jaccard_nbor_ss].\n",
            "Secret -> 03851lbmu2d9j69u84f9nb8qegd50mkr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start data upload"
      ],
      "metadata": {
        "id": "lBgEatJVi5M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "filter_out_chars = ['\\\"', '\\[', '\\]']\n",
        "pattern = '[' +  ''.join(filter_out_chars) +  ']'\n",
        "\n",
        "try:\n",
        "    f = open(\"./dataset.csv.zip\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Datafile not found - downloading!\")\n",
        "    !wget \"https://my.graph.place/dl/dataset.csv.zip\"\n",
        "\n",
        "with pd.read_csv(\"./dataset.csv.zip\", compression='zip', delimiter=',', keep_default_na=False, na_values='\\\\N', chunksize=chunk_size) as df:\n",
        "\n",
        "      for chunk in df:\n",
        "\n",
        "        counter += 1\n",
        "        recipe = []\n",
        "        recipe_keyword = []\n",
        "        recipe_ingredient = []\n",
        "        howto_cook = []\n",
        "        step = 0\n",
        "\n",
        "        for row in chunk.itertuples(index=False):\n",
        "            recipe.append((row[0]+1, {\"title\": row[1], \"link\": row[4], \"source\": row[5]}))\n",
        "            \n",
        "            # do some data cleaning based on pattern and filter_out_chars (problem with Pandas recognising list as string)\n",
        "            item_list = list(row[2].split(\",\"))\n",
        "            for item in item_list:\n",
        "                item = re.sub(pattern, '', item).strip()\n",
        "                recipe_ingredient.append((row[0]+1, item))\n",
        "\n",
        "            item_list = list(row[6].split(\",\"))\n",
        "            for item in item_list:\n",
        "                # do some data cleaning based on pattern and filter_out_chars (problem with Pandas recognising list as string)\n",
        "                item = re.sub(pattern, '', item).strip()\n",
        "                recipe_keyword.append((row[0]+1, item))\n",
        "            \n",
        "            item_list = list(row[3].split(\",\"))\n",
        "            for item in item_list:\n",
        "                step += 1\n",
        "                item = re.sub(pattern, '', item).strip()\n",
        "                howto_cook.append((row[0]+1, item, {\"step\": step}))\n",
        "            step = 0\n",
        "        # Upsert chunk_size of records\n",
        "        tgconn.upsertVertices(\"recipes\", recipe)\n",
        "        tgconn.upsertEdges(\"recipes\", \"recipe_keyword\", \"keywords\", recipe_keyword)\n",
        "        tgconn.upsertEdges(\"recipes\", \"recipe_ingredient\", \"ingredients\", recipe_ingredient)\n",
        "        tgconn.upsertEdges(\"recipes\", \"howto_cook\", \"directions\", howto_cook)\n",
        "        \n",
        "        print(\"------ Chunk \" + str(counter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UwFcGb0i7X4",
        "outputId": "044688b4-7c3a-4199-9c41-c72c9f35039c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datafile not found - downloading!\n",
            "--2022-05-06 04:39:57--  https://my.graph.place/dl/dataset.csv.zip\n",
            "Resolving my.graph.place (my.graph.place)... 5.9.78.163\n",
            "Connecting to my.graph.place (my.graph.place)|5.9.78.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4234329 (4.0M) [application/zip]\n",
            "Saving to: ‘dataset.csv.zip’\n",
            "\n",
            "dataset.csv.zip     100%[===================>]   4.04M  3.48MB/s    in 1.2s    \n",
            "\n",
            "2022-05-06 04:39:58 (3.48 MB/s) - ‘dataset.csv.zip’ saved [4234329/4234329]\n",
            "\n",
            "------ Chunk 1\n",
            "------ Chunk 2\n",
            "------ Chunk 3\n",
            "------ Chunk 4\n",
            "------ Chunk 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done"
      ],
      "metadata": {
        "id": "SohJJkT6DobP"
      }
    }
  ]
}